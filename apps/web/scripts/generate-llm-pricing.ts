// eslint-disable no-process-env
// Run with: `pnpm --filter inbox-zero-ai exec tsx scripts/generate-llm-pricing.ts`
import { writeFile } from "node:fs/promises";
import { fileURLToPath } from "node:url";
import {
  OPENROUTER_MODEL_ID_BY_SUPPORTED_MODEL,
  STATIC_MODEL_PRICING,
} from "../utils/llms/supported-model-pricing";

const OPENROUTER_MODELS_URLS = [
  "https://openrouter.ai/api/v1/models/list-models-user",
  "https://openrouter.ai/api/v1/models",
];
const OUTPUT_FILE = new URL("../utils/llms/pricing.generated.ts", import.meta.url);

type OpenRouterModel = {
  id: string;
  pricing?: {
    prompt?: string | number | null;
    completion?: string | number | null;
    input_cache_read?: string | number | null;
  };
};

type OpenRouterModelsResponse = {
  data: OpenRouterModel[];
};

type ModelPricing = {
  input: number;
  output: number;
  cachedInput: number;
};

async function main() {
  const headers: Record<string, string> = {
    Accept: "application/json",
  };

  if (process.env.OPENROUTER_API_KEY) {
    headers.Authorization = `Bearer ${process.env.OPENROUTER_API_KEY}`;
  }

  const payload = await fetchOpenRouterModels(headers);
  const pricingByModel = buildPricingMap(payload);
  const fileContents = renderGeneratedFile(pricingByModel);

  await writeFile(OUTPUT_FILE, fileContents, "utf8");

  console.log(
    `Generated ${Object.keys(pricingByModel).length} pricing entries at ${fileURLToPath(OUTPUT_FILE)}`,
  );
}

async function fetchOpenRouterModels(headers: Record<string, string>) {
  let lastError: Error | null = null;

  for (const url of OPENROUTER_MODELS_URLS) {
    const response = await fetch(url, { headers });
    if (response.ok) {
      return (await response.json()) as OpenRouterModelsResponse;
    }

    if (response.status === 404) continue;

    lastError = new Error(
      `Failed to fetch OpenRouter models from ${url}: [${response.status}] ${await response.text()}`,
    );
  }

  if (lastError) throw lastError;

  throw new Error(
    `Failed to fetch OpenRouter models from all endpoints: ${OPENROUTER_MODELS_URLS.join(", ")}`,
  );
}

function buildPricingMap(payload: OpenRouterModelsResponse) {
  const openRouterPricingByModelId: Record<string, ModelPricing> = {};

  for (const model of payload.data) {
    const pricing = parsePricing(model.pricing);
    if (!pricing) continue;
    openRouterPricingByModelId[model.id] = pricing;
  }

  const supportedModelPricing: Record<string, ModelPricing> = {};
  const unresolvedModels: string[] = [];
  const supportedModelIds = Object.keys(STATIC_MODEL_PRICING).sort((a, b) =>
    a.localeCompare(b),
  );

  for (const supportedModelId of supportedModelIds) {
    const candidateModelIds = buildOpenRouterModelIdCandidates(supportedModelId);
    const matchedPricing = candidateModelIds
      .map((candidateModelId) => openRouterPricingByModelId[candidateModelId])
      .find(Boolean);

    if (!matchedPricing) {
      unresolvedModels.push(supportedModelId);
      continue;
    }

    supportedModelPricing[supportedModelId] = matchedPricing;
  }

  if (unresolvedModels.length) {
    console.log(
      `No OpenRouter pricing match for ${unresolvedModels.length} supported models`,
    );
  }

  return supportedModelPricing;
}

function parsePricing(pricing: OpenRouterModel["pricing"]) {
  if (!pricing) return null;

  const input = parsePrice(pricing.prompt);
  const output = parsePrice(pricing.completion);
  if (input === null || output === null) return null;

  const cachedInput = parsePrice(pricing.input_cache_read) ?? input;

  return {
    input,
    output,
    cachedInput,
  } satisfies ModelPricing;
}

function parsePrice(value: string | number | null | undefined) {
  if (typeof value === "number") return Number.isFinite(value) ? value : null;
  if (typeof value !== "string") return null;

  const parsed = Number.parseFloat(value);
  return Number.isFinite(parsed) ? parsed : null;
}

function buildOpenRouterModelIdCandidates(supportedModelId: string): string[] {
  const noOnlineSuffix = supportedModelId.endsWith(":online")
    ? supportedModelId.slice(0, -":online".length)
    : supportedModelId;

  const candidates = [
    OPENROUTER_MODEL_ID_BY_SUPPORTED_MODEL[supportedModelId],
    supportedModelId,
    noOnlineSuffix,
  ].filter(Boolean) as string[];

  if (!noOnlineSuffix.includes("/")) {
    candidates.push(
      `openai/${noOnlineSuffix}`,
      `anthropic/${noOnlineSuffix}`,
      `google/${noOnlineSuffix}`,
      `meta-llama/${noOnlineSuffix}`,
      `moonshotai/${noOnlineSuffix}`,
    );
  }

  return [...new Set(candidates)];
}

function renderGeneratedFile(pricingByModel: Record<string, ModelPricing>) {
  const serializedPricing = JSON.stringify(pricingByModel, null, 2);

  return [
    "// This file is auto-generated by scripts/generate-llm-pricing.ts",
    "// Do not edit this file manually.",
    "// Contains pricing only for models we support (current + historical).",
    "",
    "export type ModelPricing = {",
    "  input: number;",
    "  output: number;",
    "  cachedInput: number;",
    "};",
    "",
    `export const OPENROUTER_MODEL_PRICING: Record<string, ModelPricing> = ${serializedPricing};`,
    "",
  ].join("\n");
}

main().catch((error) => {
  console.error(error);
  process.exitCode = 1;
});
