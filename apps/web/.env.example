NEXT_PUBLIC_BASE_URL=http://localhost:3000

DATABASE_URL="postgresql://postgres:password@localhost:5432/inboxzero?schema=public"
DIRECT_URL="postgresql://postgres:password@localhost:5432/inboxzero?schema=public"
# Docker Compose credentials (defaults shown; POSTGRES_PASSWORD must match DATABASE_URL):
# POSTGRES_USER=postgres
# POSTGRES_PASSWORD=password # change this for production
# POSTGRES_DB=inboxzero
# Optional Docker Compose host port overrides:
# WEB_PORT=3000
# POSTGRES_PORT=5432
# REDIS_PORT=6380
# REDIS_HTTP_PORT=8079

UPSTASH_REDIS_URL="http://localhost:8079"
UPSTASH_REDIS_TOKEN= # openssl rand -hex 32
REDIS_URL= # used for subscriptions: rediss://:password@host:port
QSTASH_TOKEN=
QSTASH_CURRENT_SIGNING_KEY=
QSTASH_NEXT_SIGNING_KEY=

GOOGLE_CLIENT_ID=
GOOGLE_CLIENT_SECRET=
GOOGLE_PUBSUB_TOPIC_NAME="projects/abc/topics/xyz"
GOOGLE_PUBSUB_VERIFICATION_TOKEN= # openssl rand -hex 32

MICROSOFT_CLIENT_ID=
MICROSOFT_CLIENT_SECRET=
MICROSOFT_WEBHOOK_CLIENT_STATE= # openssl rand -hex 32
MICROSOFT_TENANT_ID= # leave empty for "common"

# Slack (optional) — see docs/slack/setup.md
SLACK_CLIENT_ID=
SLACK_CLIENT_SECRET=
SLACK_SIGNING_SECRET=

# Teams (optional) — falls back to MICROSOFT_CLIENT_ID/SECRET if unset
TEAMS_CLIENT_ID=
TEAMS_CLIENT_SECRET=

AUTH_SECRET= # openssl rand -hex 32
EMAIL_ENCRYPT_SECRET= # openssl rand -hex 32
EMAIL_ENCRYPT_SALT= # openssl rand -hex 16
INTERNAL_API_KEY= # openssl rand -hex 32
API_KEY_SALT= # openssl rand -hex 32
CRON_SECRET= # openssl rand -hex 32 -note: cron disabled if not set

NEXT_PUBLIC_BYPASS_PREMIUM_CHECKS=true
# DISABLE_LOG_ZOD_ERRORS=true # Uncomment to disable Zod validation error logging
# DIGEST_MAX_SUMMARIES_PER_24H=50
# WEBHOOK_URL=
# INTERNAL_API_URL= # Preferred callback base URL for QStash (when set) and server-side fallback calls

# =============================================================================
# LLM Configuration - Uncomment ONE provider block
# =============================================================================

LLM_API_KEY=

# --- OpenRouter ---
# DEFAULT_LLM_PROVIDER=openrouter
# DEFAULT_LLM_MODEL=anthropic/claude-sonnet-4.5
# ECONOMY_LLM_PROVIDER=openrouter
# ECONOMY_LLM_MODEL=anthropic/claude-haiku-4.5

# --- Anthropic ---
# DEFAULT_LLM_PROVIDER=anthropic
# DEFAULT_LLM_MODEL=claude-sonnet-4-5-20250929
# ECONOMY_LLM_PROVIDER=anthropic
# ECONOMY_LLM_MODEL=claude-haiku-4-5-20251001

# --- OpenAI ---
# DEFAULT_LLM_PROVIDER=openai
# DEFAULT_LLM_MODEL=gpt-5.1
# ECONOMY_LLM_PROVIDER=openai
# ECONOMY_LLM_MODEL=gpt-5-mini
# OPENAI_ZERO_DATA_RETENTION=

# --- Azure OpenAI ---
# DEFAULT_LLM_PROVIDER=azure
# DEFAULT_LLM_MODEL=gpt-5-mini # Usually your Azure deployment name
# ECONOMY_LLM_PROVIDER=azure
# ECONOMY_LLM_MODEL=gpt-5-mini # Usually your Azure deployment name
# AZURE_RESOURCE_NAME=
# AZURE_API_VERSION=

# --- Google Gemini (AI Studio) ---
# DEFAULT_LLM_PROVIDER=google
# DEFAULT_LLM_MODEL=gemini-3.0-flash-preview
# ECONOMY_LLM_PROVIDER=google
# ECONOMY_LLM_MODEL=gemini-2.5-flash
# GOOGLE_API_KEY=

# --- Google Vertex AI ---
# DEFAULT_LLM_PROVIDER=vertex
# DEFAULT_LLM_MODEL=gemini-3-flash
# ECONOMY_LLM_PROVIDER=vertex
# ECONOMY_LLM_MODEL=gemini-2.5-flash
# GOOGLE_VERTEX_PROJECT=
# GOOGLE_VERTEX_LOCATION=us-central1
# GOOGLE_VERTEX_CLIENT_EMAIL=
# GOOGLE_VERTEX_PRIVATE_KEY="-----BEGIN PRIVATE KEY-----\n...\n-----END PRIVATE KEY-----\n"
# GOOGLE_APPLICATION_CREDENTIALS= # Alternative to inline credentials

# --- Bedrock ---
# DEFAULT_LLM_PROVIDER=bedrock
# DEFAULT_LLM_MODEL=global.anthropic.claude-sonnet-4-5-20250929-v1:0
# ECONOMY_LLM_PROVIDER=bedrock
# ECONOMY_LLM_MODEL=global.anthropic.claude-haiku-4-5-20251001-v1:0
# BEDROCK_ACCESS_KEY=
# BEDROCK_SECRET_KEY=
# BEDROCK_REGION=us-west-2

# --- Vercel AI Gateway ---
# DEFAULT_LLM_PROVIDER=aigateway
# DEFAULT_LLM_MODEL=anthropic/claude-sonnet-4.5
# ECONOMY_LLM_PROVIDER=aigateway
# ECONOMY_LLM_MODEL=anthropic/claude-haiku-4.5

# --- Groq ---
# DEFAULT_LLM_PROVIDER=groq
# DEFAULT_LLM_MODEL=llama-3.3-70b-versatile
# ECONOMY_LLM_PROVIDER=groq
# ECONOMY_LLM_MODEL=llama-3.1-8b-instant

# --- Ollama (Local LLM) ---
# DEFAULT_LLM_PROVIDER=ollama
# OLLAMA_MODEL=llama3
# OLLAMA_BASE_URL=http://localhost:11434/api

# --- OpenAI-Compatible (e.g. LM Studio, vLLM, LocalAI) ---
# DEFAULT_LLM_PROVIDER=openai-compatible
# OPENAI_COMPATIBLE_BASE_URL=http://localhost:1234/v1
# OPENAI_COMPATIBLE_MODEL=llama-3.2-3b-instruct

# --- Optional Provider Fallback Chain (ordered) ---
# Format: provider:model,provider:model (explicit model required)
# DEFAULT_LLM_FALLBACKS=openrouter:anthropic/claude-sonnet-4.5,openai:gpt-5.1
# ECONOMY_LLM_FALLBACKS=openrouter:google/gemini-2.5-flash
# CHAT_LLM_FALLBACKS=openrouter:anthropic/claude-haiku-4.5
# NANO_LLM_PROVIDER=openai
# NANO_LLM_MODEL=gpt-5-nano

# AI_NANO_WEEKLY_SPEND_LIMIT_USD=3

# =============================================================================
# Everything below is optional
# =============================================================================

# Tinybird
TINYBIRD_TOKEN=
TINYBIRD_BASE_URL=https://api.us-east.tinybird.co/
TINYBIRD_ENCRYPT_SECRET= # openssl rand -hex 32
TINYBIRD_ENCRYPT_SALT= # openssl rand -hex 16

# Sentry (error tracking)
SENTRY_AUTH_TOKEN=
SENTRY_ORGANIZATION=
SENTRY_PROJECT=
NEXT_PUBLIC_SENTRY_DSN=

# Axiom (logging)
NEXT_PUBLIC_AXIOM_DATASET=
NEXT_PUBLIC_AXIOM_TOKEN=

# Transactional emails
RESEND_API_KEY=
NEXT_PUBLIC_IS_RESEND_CONFIGURED= # for frontend - enables relevant features

# Marketing emails
LOOPS_API_SECRET=

# PostHog (analytics)
# NEXT_PUBLIC_POSTHOG_KEY=
# NEXT_PUBLIC_POSTHOG_HERO_AB=
# NEXT_PUBLIC_POSTHOG_ONBOARDING_SURVEY_ID=
# POSTHOG_API_SECRET=
# POSTHOG_PROJECT_ID=

# Crisp support chat
# NEXT_PUBLIC_CRISP_WEBSITE_ID=

# Sanity config for blog. (Not needed. Only for blog):
# NEXT_PUBLIC_SANITY_PROJECT_ID=
# NEXT_PUBLIC_SANITY_DATASET="production"

# Feature flags
# NEXT_PUBLIC_DIGEST_ENABLED=true
# NEXT_PUBLIC_MEETING_BRIEFS_ENABLED=true
# NEXT_PUBLIC_FOLLOW_UP_REMINDERS_ENABLED=true
# NEXT_PUBLIC_INTEGRATIONS_ENABLED=false # beta
# NEXT_PUBLIC_SMART_FILING_ENABLED=false # beta
# NEXT_PUBLIC_CLEANER_ENABLED=false # beta

# OAUTH_PROXY_URL= # For preview deployments to proxy OAuth callbacks
# IS_OAUTH_PROXY_SERVER=false # Set to true on the server that acts as the OAuth proxy (e.g., staging)
# ADDITIONAL_TRUSTED_ORIGINS=https://*.vercel.app # Comma-separated list of trusted origins for CORS (supports wildcards)
# MOBILE_AUTH_ORIGIN=inboxzero:// # Mobile auth deep link origin
